input {

	tcp {
		port => 5000
        type => syslog
	}

	udp {
		port => 12201
        queue_size => 50000
        type => "nginx"
        # host => "192.168.50.248"

	}

    gelf {

    }

}

filter {
grok {
  match => {
      "message" => "%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\]\"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]}\"%{DATA:[nginx][access][referrer]}\" \"%{DATA:[nginx][access][agent]}\"\"%{NUMBER:[nginx][access][request_time]}\" \"%{NUMBER:[nginx][access][upstream_connect_time]}\""
  }
  remove_field => "message"
}
mutate {
      add_field => { "read_timestamp" => "%{@timestamp}" }
    }
  date {
      match => [ "[nginx][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
      remove_field => "[nginx][access][time]"
    }
  useragent {
      source => "[nginx][access][agent]"
      target => "[nginx][access][user_agent]"
      remove_field => "[nginx][access][agent]"
    }
  geoip {
      source => "[nginx][access][remote_ip]"
      target => "[nginx][access][geoip]"
    }
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
        index => "nginx"

	}
}

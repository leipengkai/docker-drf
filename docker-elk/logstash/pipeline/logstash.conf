input {
	beats {
		port => 5044
	}
}

filter {
    grok {
        # 2019-08-21 11:26:09.717
        # match => ["message", "%{TIMESTAMP_ISO8601:logdate}"]
        
        # 我的是json格式的日志
        # time_local字段 按 21/Aug/2019:15:56:09 +0800 来匹配,并保存到logdate
        match => ["time_local", "%{HTTPDATE:logdate}"]
    }
    date {
        # logdate将上面匹配的,转换成此格式
        match => ["logdate", "dd/MMM/yyyy:HH:mm:ss Z"]  # Z是时区，匹配这里的+0800，中国的东八区
        # logdate上的内容,替换掉@timestamp内容
        target => "@timestamp"
        # 删除logdate字段
        remove_field => ["logdate"]
    }
}

output {
  if "access" in [tags] {      
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      #index => "all_logstash-%{indexDay}"    # 不用有"_"或indexDay,解决不能导入到ES问题
      #index => "all-logstash-%{+yyyy.MM.dd}" # ok
      index => "nginx-access-%{+yyyy.MM}"      # 为了用filebeat自带modules,而设置的index名称
    }
  }
  if "error" in [tags] {      
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "nginx-error-%{+yyyy.MM}"      # 为了用filebeat自带modules,而设置的index名称
    }
  }
  # 为了启动时,输入的日志不在终端显示,将其关闭. 开启仅仅是为了测试
  #stdout {
    #codec => rubydebug
  #}
}
